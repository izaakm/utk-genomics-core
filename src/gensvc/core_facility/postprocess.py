#!/usr/bin/env python
# coding: utf-8

'''
Step 1: Extract sequencing statistics from bcl2fastq outputs or from
BCL-Convert legacy stats.

Briefly, this script extracts tables from HTML files and splits those tables by
project. Tables for split lane runs will be saved in separate directories
according to the "Project" name.

More info: bcl2fastq generates summary stats automatically. The 'raw' stats are
in the Stats directory (as json) and the summary tables for users are in the
Reports directory (html). This script scrapes most of the summary stats from
the html files in the Reports directory. The only exception is the "Top Unknown
Barcodes" table; the formatting in the html files is awkward, so we recreate
this one from json in the Stats directory.

The output of this script is organized as follows:

    SummaryStatistics
    ├── <PROJECT>
    │   ├── LaneSummary.csv
    │   ├── SampleSummary.csv
    │   └── TopUnknownBarcodes.csv
    └── all
        ├── FlowcellSummary.csv
        ├── LaneSummary.csv
        ├── SampleSummary.csv
        └── TopUnknownBarcodes.csv

Step 2: Set up the transfer directory.

The original data directory has the following structure:

    $PROJECTS/UTK0192/processed/<run_id>/BCLConvert/<sample_project>

And we need to set up the transfer directory that looks like this:

    $PROJECTS/UTK0192/processed/<project>/<run_id>/<sample_project>/fastq
'''

# Python standard library
import argparse
import json
import logging
import os
import pathlib
import re
import shutil
import sys
import warnings

# Third party
import pandas as pd


logger = logging.getLogger(__name__)

readme_text = '''
# UTK Genomics Core Sequencing data

**Methods**

Please contact the genomics at <genomicscore@utk.edu> for specific information
on library prep and instrument set up methods.

Fastq files were generated with the Illumina BCL Convert(tm) software, which
converts the Binary Base Call (BCL) files produced by Illumina(tm) instruments
to FASTQ files. The BCL Convert [support pages](https://support.illumina.com)
provide additional resources. These resources include training, compatible
products, and other considerations. Always check support pages for the latest
versions.

**Directory Structure**

    fastq/             # Gzipped fastq files
    SummaryStatistics/ # Generated by BCLConvert

**Acknowledgements**

Acknowledging the Genomics Core in publications using data produced here helps
the Core maintain internal funding. Please consider acknowledging the Core
either in the Methods section or Acknowledgements section of your publications
with text such as:

> Sequencing was performed on the Illumina iSeq/NextSeq/NovaSeq at the
> University of Tennessee Genomics Core.

> A portion of the computational work was performed in collaboration with High
> Performance and Scientific Computing (HPSC) staff at the University of
> Tennessee, Knoxville, on the Infrastructure for Scientific Applications and
> Advanced Computing (ISAAC) Next Generation cluster.
'''.strip()

def get_sample_stats(sample_stats, lane_stats):
    '''
    sample_stats : Sample Demultiplex Results
    lane_stats : Lane Conversion Results
    '''

    barcode_sequence = sample_stats['IndexMetrics'][0]['IndexSequence']
    sample_nreads = sample_stats['NumberReads']
    if sample_nreads > 0:
        lane_nclusters = lane_stats['TotalClustersPF']
        percent_lane = (sample_nreads / lane_nclusters)*100
        percent_perfect_barcode = sample_stats['IndexMetrics'][0]['MismatchCounts']['0'] / sample_stats['NumberReads'] * 100
        percent_mismatch_barcode = sample_stats['IndexMetrics'][0]['MismatchCounts']['1'] / sample_stats['NumberReads'] * 100
        yield_mbases = round(sample_stats['Yield'] / 1000000)

        # Percent bases w/ Q30
        y0 = sample_stats['ReadMetrics'][0]['YieldQ30'] / sample_stats['ReadMetrics'][0]['Yield']
        y1 = sample_stats['ReadMetrics'][1]['YieldQ30'] / sample_stats['ReadMetrics'][1]['Yield']
        percent_q30 = ((y0+y1)/2)*100

        # Mean Quality score
        q0 = sample_stats['ReadMetrics'][0]['QualityScoreSum'] / sample_stats['ReadMetrics'][0]['Yield']
        q1 = sample_stats['ReadMetrics'][1]['QualityScoreSum'] / sample_stats['ReadMetrics'][1]['Yield']
        mean_quality = (q0+q1)/2

    else:
        lane_nclusters = 0
        percent_lane = 'NA'
        percent_perfect_barcode = 'NA'
        percent_mismatch_barcode = 'NA'
        yield_mbases = 'NA'
        percent_q30 = 'NA'
        mean_quality = 'NA'

    row = {
        'Project': '',
        'Sample': sample_stats['SampleName'],
        'Barcode sequence': barcode_sequence,
        'PF Clusters': sample_nreads,
        '% of the lane': percent_lane,
        '% Perfect barcode': percent_perfect_barcode,
        '% One mismatch barcode': percent_mismatch_barcode,
        'Yield (Mbases)': yield_mbases,
        # '% PF Clusters': 'Always 100???',
        '% >= Q30 bases': percent_q30,
        'Mean Quality Score': mean_quality
    }
    return row


def make_samples_lane_summary(statsdata):
    demux_data = []
    for lane_number, lane in enumerate(statsdata['ConversionResults'], start=1):
        # print(lane_number)
        for sample in lane['DemuxResults']:
            # print(sample['SampleName'])
            demux_data.append(get_sample_stats(sample_stats=sample, lane_stats=lane))
    demux_df = pd.DataFrame(demux_data)
    return demux_df


def get_top_unknown_barcodes(statsdata, n=10):
    top_ubarcodes = []
    for lane in statsdata['UnknownBarcodes']:
        # print(lane['Lane'])
        # print(lane.keys())

        b = lane['Barcodes']

        t = pd.Series(b)
        t.name = 'Count' # Will be coerced to column name.
        t = t.to_frame()
        t = t.reset_index(names=['Sequence'])
        t['Lane'] = lane['Lane']
        top_ubarcodes.append(t.sort_values('Count', ascending=False).head(10).copy())
    table = pd.concat(top_ubarcodes).reset_index(drop=True)
    table = table[['Lane', 'Count', 'Sequence']]
    return table


def extract_tables(statsdir):
    tables = {}
    p = list(statsdir.rglob('all/all/all/lane.html'))[0]
    data = pd.read_html(p)
    # len(data)

    # data[0]
    tables['main_flowcell_summary'] = data[1]
    tables['main_lane_summary'] = data[2]

    p = list(statsdir.rglob('all/all/all/laneBarcode.html'))[0]
    data = pd.read_html(p)
    # len(data)

    # data[0]
    try:
        # print(data[1].columns)
        tables['samples_flowcell_summary'] = data[1]
    except:
        pass
    try:
        # print(data[2].columns)
        tables['samples_lane_summary'] = data[2]
    except:
        pass
    try:
        # print(data[3].columns)
        tables['samples_top_unknown_barcodes'] = data[3]
    except:
        pass

    return tables


def write_table(df, path=None, index=False):
    if path is None:
        print(df.to_string(index=index))
        return None
    else:
        logging.debug(f'Saving table data to {path}')
        return df.to_csv(path, index=index)


def cli_extract_stats(args):
    if args.statsdir is None:
        statsdir = args.rundir / 'BCLConvert/Reports/legacy'
    else:
        statsdir = args.statsdir
    logging.debug(f'statsdir={statsdir}')

    # Scrape tables from html files in the Reports directory.
    tables = extract_tables(statsdir)
    logging.debug(f'Found {len(tables)} tables.')

    # Load stats data.
    if args.statsfile:
        with open(args.statsfile) as f:
            statsdata = json.load(f)
    else:
        with open(statsdir / 'Stats/Stats.json') as f:
            statsdata = json.load(f)

    tables['stats_lane_summary'] = make_samples_lane_summary(statsdata)

    # Get unknown barcodes
    tables['stats_top_unknown_barcodes'] = get_top_unknown_barcodes(statsdata, n=10)

    # All Lanes: These files are the ones that the Genomics Core will want to
    # look at. They contain summary stats for all sequences in all lanes.
    # args.outdir.mkdir(parents=True, exist_ok=True)
    if args.outdir:
        out_all = args.outdir / 'all'
        out_all.mkdir(parents=True, exist_ok=True)
    else:
        out_all = None

    write_table(
        tables['main_flowcell_summary'],
        path=out_all / 'FlowcellSummary.csv' if out_all else None
    )
    write_table(
        tables['main_lane_summary'],
        path=out_all / 'LaneSummary.csv' if out_all else None
    )
    write_table(
        tables['samples_lane_summary'],
        path=out_all / 'SampleSummary.csv' if out_all else None
    )
    write_table(
        tables['stats_top_unknown_barcodes'],
        path=out_all / 'TopUnknownBarcodes.csv' if out_all else None
    )

    # Split Lanes: Each user's data is wholly contained in a subset of the
    # lanes. We only want to provide the summary stats relevant for the lanes
    # that contain that user's data.
    for name, grp in tables['samples_lane_summary'].groupby('Project'):
        if name == 'default':
            continue
        lanes = set(grp['Lane'])
        if args.outdir:
            out_project = args.outdir / name
            out_project.mkdir(exist_ok=True)
        else:
            out_project = None

        # Sample Summary
        write_table(
            grp,
            path=out_project / 'SampleSummary.csv' if out_project else None
        )

        # Lane Summary
        mask = tables['main_lane_summary']['Lane'].isin(lanes)
        write_table(
            tables['main_lane_summary'].loc[mask],
            path=out_project / 'LaneSummary.csv' if out_project else None
        )

        # Top Unknown Barcodes
        mask = tables['stats_top_unknown_barcodes']['Lane'].isin(lanes)
        write_table(
            tables['stats_top_unknown_barcodes'].loc[mask],
            path=out_project / 'TopUnknownBarcodes.csv' if out_project else None
        )

    return None


def link_fastq(srcdir, destdir):
    '''
    Hardlink the fastq files from the source directory to the destination directory.

    Path.hardlink_to(target)
        Make this path a hard link to the same file as target.
    '''
    filelist = list(srcdir.glob('*.fastq.gz'))
    links = []
    if len(filelist) == 0:
        return links

    destdir.mkdir(parents=True, exist_ok=True)
    for fastq in filelist:
        target = destdir / fastq.name
        # DRY RUN
        # print('mkdir -p', target.parent)
        # print(target, '->', fastq)
        # Hardlink:
        if target.is_file():
            target.unlink()
        target.hardlink_to(fastq)
        links.append(target)
    return links


def link_csv(srcdir, destdir):
    '''
    Hardlink the csv files from the source directory to the destination directory.
    '''
    for csv in srcdir.glob('*.csv'):
        target = destdir / csv.name
        # DRY RUN
        # print('mkdir -p', target.parent)
        # print(target, '->', csv)
        # Hardlink:
        target.parent.mkdir(parents=True, exist_ok=True)
        if target.is_file():
            target.unlink()
        target.hardlink_to(csv)


def make_transfer_commands(runid, sample_project, projectid):
    '''
    Consider adding conditionals for the project account. EG, set read/write
    permissions differently for specific projects.


    Given the following processed data:

        /lustre/isaac24/proj/UTK0192/data/processed/<RUNID>
        /lustre/isaac24/proj/UTK0192/data/processed/<RUNID>/BCLConvert/<SAMPLE_PROJECT>

    Create the transfer script:

        /lustre/isaac24/proj/UTK0192/data/processed/<RUNID>/transfer/<PROJECTID>/transfer-<SAMPLE_PROJECT>.sh

    The transfer script transfers data from the source directory in UTK0192 to the destination project:

        /lustre/isaac24/proj/UTK0192/data/processed/<RUNID>/transfer/<PROJECTID>/<SAMPLE_PROJECT>
        /lustre/isaac24/proj/<PROJECTID>/UTKGenomicsCoreSequencingData/<RUNID>/<SAMPLE_PROJECT>

    Specific directories and files for reference:

        /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5
        /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/BCLConvert/UTK0341_vonarnim_Alex_250507
        /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/transfer/UTK0341/UTK0341_vonarnim_Alex_250507
        /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/transfer/UTK0341/transfer-UTK0341_vonarnim_Alex_250507.sh
        /lustre/isaac24/proj/UTK0341/UTKGenomicsCoreSequencingData/250507_VL00838_25_AAGY5MJM5/UTK0341_vonarnim_Alex_250507
    '''
    if projectid == 'UTK0204':
        # Make all of Beever's files group writable.
        rsync_cmd = 'rsync -auv --no-owner --no-group --chmod=F660 --chmod=D3770 "${srcdir}/" "${dstdir}/"'
    else:
        rsync_cmd = 'rsync -auv --no-owner --no-group --chmod=F640 --chmod=D3750 "${srcdir}/" "${dstdir}/"'
    lines = [
        '#!/usr/bin/env bash',
        '',
        'set -x',
        'set -e',
        'set -u',
        'set -o pipefail',
        '',
        'umask 002',
        '',
        'declare logfile="$(basename -s .sh "$0").log"',
        '',
        '# Redirect stdout and stderr to the logfile.',
        'exec 1>>"$logfile"',
        'exec 2>>"$logfile"',
        '',
        f'declare runid="{runid}"',
        f'declare projectid="{projectid}"',
        f'declare sample_project="{sample_project}"',
        '',
        'declare srcdir="/lustre/isaac24/proj/UTK0192/data/processed/${runid}/transfer/${projectid}/${sample_project}"',
        'declare projdir="/lustre/isaac24/proj/${projectid}"',
        'declare dstdir="/lustre/isaac24/proj/${projectid}/UTKGenomicsCoreSequencingData/${runid}/${sample_project}"',
        '',
        'mkdir -p "${dstdir}"',
        rsync_cmd,
        '',
        '# Fix ownership',
        'chown --reference "${projdir}" "${projdir}/UTKGenomicsCoreSequencingData"',
        'find "${projdir}/UTKGenomicsCoreSequencingData/${runid}" -user $(whoami) -exec chown --reference "${projdir}" {} \\;',
        '',
        '# Verify ownership',
        'find "${projdir}/UTKGenomicsCoreSequencingData/${runid}" -print0 | xargs -0 ls -ld',
        '',
        'touch "${runid}.ISAACTransferComplete"',
        '',
        'exit 0',
    ]
    return '\n'.join(lines)


def cli_setup_transfer_dir(args):
    '''
    Examples
    --------
    /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5
    /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/BCLConvert/UTK0341_vonarnim_Alex_250507
    /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/transfer/UTK0341/UTK0341_vonarnim_Alex_250507
    /lustre/isaac24/proj/UTK0192/data/processed/250507_VL00838_25_AAGY5MJM5/transfer/UTK0341/transfer-UTK0341_vonarnim_Alex_250507.sh
    /lustre/isaac24/proj/UTK0341/UTKGenomicsCoreSequencingData/250507_VL00838_25_AAGY5MJM5/UTK0341_vonarnim_Alex_250507
    '''
    # rundir = pathlib.Path(sys.argv[1]).resolve()
    rundir = args.rundir.resolve()
    runid = rundir.name

    for dirname in rundir.glob('BCLConvert/*'):
        do_transfer = False
        if not dirname.is_dir():
            continue
        elif dirname.name == 'Logs':
            continue
        elif dirname.name == 'Reports':
            continue

        sample_project = dirname.name

        if re.match(r'^UTK\d{4}', sample_project):
            projectid = re.match(r'^(UTK\d{4})', sample_project).group(1)
            do_transfer = True
        elif re.match(r'^UTK', sample_project):
            projectid = 'unknown_project'
        else:
            projectid = 'external'

        path_to_transfer_fastq = rundir / 'transfer' / projectid / sample_project / 'fastq'
        path_to_transfer_readme = rundir / 'transfer' / projectid / sample_project / 'README.md'
        path_to_transfer_script = rundir / 'transfer' / projectid / f'transfer-{sample_project}.sh'

        if args.dry_run:
            print('[DRY RUN] link files ...')
        else:
            links = link_fastq(dirname, path_to_transfer_fastq)
            # Also link the "Undetermined" fastq files.
            links += link_fastq(dirname.parent, path_to_transfer_fastq)
            print(f'Linked {len(links)} fastq files from "{dirname}" into "{path_to_transfer_fastq}".', file=sys.stderr)

        if do_transfer:
            # Make the transfer script.
            transfer_script = make_transfer_commands(runid, sample_project, projectid)
            if args.dry_run:
                print(f'[DRY RUN] Would write readme to {path_to_transfer_readme}')
                print(f'[DRY RUN] Would write transfer script to {path_to_transfer_script}')
                print(transfer_script)
            else:
                # The directory should already exist *if* there were fastq files.
                path_to_transfer_script.parent.mkdir(parents=True, exist_ok=True)
                with open(path_to_transfer_readme, 'w') as f:
                    print(readme_text, file=f)
                with open(path_to_transfer_script, 'w') as f:
                    print(transfer_script, file=f)


    for dirname in rundir.glob('SummaryStatistics/*'):
        # do_transfer = False
        sample_project = dirname.name
        if sample_project == 'all':
            continue
        elif re.match(r'^UTK\d{4}', sample_project):
            project = re.match(r'^(UTK\d{4})', sample_project).group(1)
            # do_transfer = True
        elif re.match(r'^UTK', sample_project):
            project = 'unknown_project'
        else:
            project = 'external'

        transfer_stats = rundir / 'transfer' / project / sample_project / 'SummaryStatistics'

        if args.dry_run:
            print(f"{dirname} -> {transfer_stats}")
        else:
            link_csv(dirname, transfer_stats)

        # Don't worry about writing the transfer script bc there really
        # shouldn't ever be a time where we have STATS but NO DATA.

    return None


def parse_args():
    def path_or_stdout(path):
        if path is None:
            return None
        elif path == '-':
            return None
        else:
            return pathlib.Path(path)

    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'rundir',
        action='store',
        type=pathlib.Path,
    )

    parser.add_argument(
        '--dry-run', '-n',
        action='store_true',
        help='Just print'
    )
    parser.add_argument(
        '--extract-stats',
        action='store_true',
        default=True
    )

    parser.add_argument(
        '--no-extract-stats',
        dest='extract_stats',
        action='store_false'
    )

    parser.add_argument(
        '--statsdir',
        action='store',
        type=pathlib.Path,
        help=(
            'The output directory containing the "Reports" and "Stats"'
            ' subdirectories. For BCL-Convert this is, eg:'
            ' "<bcl-convert-output>/Reports/legacy".'
        )
    )

    parser.add_argument(
        '--statsfile',
        action='store',
        type=pathlib.Path,
        help=(
            'OPTIONAL: Statistics json file. Defaults to "<statsdir>/Stats/Stats.json".'
        )
    )

    parser.add_argument(
        '--outdir',
        action='store',
        default='SummaryStatistics',
        type=path_or_stdout,
        help='Directory in which to put the output files. if "-" then print to stdout.'
    )

    parser.add_argument(
        '--setup-transfer-dir',
        action='store_true',
        default=True
    )

    parser.add_argument(
        '--no-setup-transfer-dir',
        dest='setup_transfer_dir',
        action='store_false'
    )

    parser.add_argument(
        '--genomics-core-dirname',
        action='store',
        default='UTKGenomicsCoreSequencingData',
        help=(
            'The name of the directory where the data will be transferred to. Defaults to "UTKGenomicsCoreSequencingData".'
        )
    )

    parser.add_argument(
        '--debug',
        action='store_true',
        default=False
    )

    args = parser.parse_args()
    if args.debug:
        print('args:', json.dumps(args.__dict__, indent=2, default=str), sep='\n')

    return args


def main():
    args = parse_args()

    logging.basicConfig(level=logging.DEBUG)
    logger.info('Started')

    if args.extract_stats:
        if args.dry_run:
            warnings.warn('--dry-run is not implemented for "SummaryStatistic" ... SKIPPING.')
        else:
            cli_extract_stats(args)

    if args.setup_transfer_dir:
        cli_setup_transfer_dir(args)

    logger.info('Finished')

    return 0


if __name__ == '__main__':
    res = main()
    sys.exit(res)
